<!doctype html>
<html lang="en">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Liste - http://localhost:1313/">
    <title>Fairness in Social Influence Maximization via Optimal Transport | Bloggin on Responsible AI</title>
    <meta name="description" content="Bloggin on Responsible AI">
    <meta property="og:url" content="http://localhost:1313/posts/fairness-in-social-influence-maximization-via-optimal-transport/">
  <meta property="og:site_name" content="Bloggin on Responsible AI">
  <meta property="og:title" content="Fairness in Social Influence Maximization via Optimal Transport">
  <meta property="og:description" content="Authors: Guillaume MARIN-BERTIN &amp; Jaishan BURTON ELMO Table of Contents
1. Introduction 2. Mutual Fairness: A New Metric 2.1 Why Make a New Metric? 2.2 Proposed Fairness Metric 2.3 Short Example 3. Metric in Practice 3.1 Mutual Fairness in Practice 3.2 Impact of β 4. Improving Fairness with S3D 4.1 Stochastic Seed Selection Descent (S3D) 4.2 Experimentation 4.3 Impact of S3D 5. Conclusion References This is a blog post about the article “Fairness in Social Influence Maximization via Optimal Transport” published by Shubham Chowdhary et al. in 2024 and available here.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-03-15T17:27:56+01:00">
    <meta property="article:modified_time" content="2025-03-15T17:27:56+01:00">

    
  <meta itemprop="name" content="Fairness in Social Influence Maximization via Optimal Transport">
  <meta itemprop="description" content="Authors: Guillaume MARIN-BERTIN &amp; Jaishan BURTON ELMO Table of Contents
1. Introduction 2. Mutual Fairness: A New Metric 2.1 Why Make a New Metric? 2.2 Proposed Fairness Metric 2.3 Short Example 3. Metric in Practice 3.1 Mutual Fairness in Practice 3.2 Impact of β 4. Improving Fairness with S3D 4.1 Stochastic Seed Selection Descent (S3D) 4.2 Experimentation 4.3 Impact of S3D 5. Conclusion References This is a blog post about the article “Fairness in Social Influence Maximization via Optimal Transport” published by Shubham Chowdhary et al. in 2024 and available here.">
  <meta itemprop="datePublished" content="2025-03-15T17:27:56+01:00">
  <meta itemprop="dateModified" content="2025-03-15T17:27:56+01:00">
  <meta itemprop="wordCount" content="2513">
    
    <link rel="canonical" href="http://localhost:1313/posts/fairness-in-social-influence-maximization-via-optimal-transport/">
    <link rel="icon" href="http://localhost:1313//assets/favicon.ico">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link href="https://www.google-analytics.com" rel="preconnect" crossorigin>
    <link rel="alternate" type="application/atom+xml" title="Bloggin on Responsible AI" href="http://localhost:1313//atom.xml" />
    <link rel="alternate" type="application/json" title="Bloggin on Responsible AI" href="http://localhost:1313//feed.json" />
    <link rel="shortcut icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII=">
    
    
    <style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:#f5f5f5;color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5,strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a,a:visited{color:inherit}a:hover,a.heading-link{text-decoration:none}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:square}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:2;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:120px;width:120px;position:relative;margin:-10px 0 0 15px;float:right;border-radius:50%} </style>
  
    
  
  
  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "BlogPosting",
      "articleSection": "posts",
      "name": "Fairness in Social Influence Maximization via Optimal Transport",
      "headline": "Fairness in Social Influence Maximization via Optimal Transport",
      "alternativeHeadline": "",
      "description": "\u003ch3 id=\u0022authors-guillaume-marin-bertin--jaishan-burton-elmo\u0022\u003eAuthors: Guillaume MARIN-BERTIN \u0026amp; Jaishan BURTON ELMO\u003c\/h3\u003e\n\u003cp\u003e\u003cstrong\u003eTable of Contents\u003c\/strong\u003e\u003c\/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\u0022#introduction\u0022\u003e1. Introduction\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#mutual-fairness\u0022\u003e2. Mutual Fairness: A New Metric\u003c\/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\u0022#why-make-a-new-metric\u0022\u003e2.1 Why Make a New Metric?\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#proposed-fairness-metric\u0022\u003e2.2 Proposed Fairness Metric\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#short-example\u0022\u003e2.3 Short Example\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ul\u003e\n\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#fairness-evaluation\u0022\u003e3. Metric in Practice\u003c\/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\u0022#mutual-fairness-practice\u0022\u003e3.1 Mutual Fairness in Practice\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#impact-of-beta\u0022\u003e3.2 Impact of β\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ul\u003e\n\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#s3d-algorithm\u0022\u003e4. Improving Fairness with S3D\u003c\/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\u0022#stochastic-seed-selection-descent\u0022\u003e4.1 Stochastic Seed Selection Descent (S3D)\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#experimentation\u0022\u003e4.2 Experimentation\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#impact-of-s3d\u0022\u003e4.3 Impact of S3D\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ul\u003e\n\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#conclusion\u0022\u003e5. Conclusion\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e\u003ca href=\u0022#references\u0022\u003eReferences\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ul\u003e\n\u003cp\u003eThis is a blog post about the article “Fairness in Social Influence Maximization via Optimal Transport” published by Shubham Chowdhary et al. in 2024 and available \u003ca href=\u0022https:\/\/neurips.cc\/virtual\/2024\/poster\/94521\u0022\u003e\u003cstrong\u003ehere\u003c\/strong\u003e\u003c\/a\u003e.\u003c\/p\u003e",
      "inLanguage": "en-us",
      "isFamilyFriendly": "true",
      "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "http:\/\/localhost:1313\/posts\/fairness-in-social-influence-maximization-via-optimal-transport\/"
      },
      "author" : {
          "@type": "Person",
          "name": ""
      },
      "creator" : {
          "@type": "Person",
          "name": ""
      },
      "accountablePerson" : {
          "@type": "Person",
          "name": ""
      },
      "copyrightHolder" : "Bloggin on Responsible AI",
      "copyrightYear" : "2025",
      "dateCreated": "2025-03-15T17:27:56.00Z",
      "datePublished": "2025-03-15T17:27:56.00Z",
      "dateModified": "2025-03-15T17:27:56.00Z",
      "publisher":{
          "@type":"Organization",
          "name": "Bloggin on Responsible AI",
          "url": "http://localhost:1313/",
          "logo": {
              "@type": "ImageObject",
              "url": "http:\/\/localhost:1313\/assets\/favicon.ico",
              "width":"32",
              "height":"32"
          }
      },
      "image": "http://localhost:1313/assets/favicon.ico",
      "url" : "http:\/\/localhost:1313\/posts\/fairness-in-social-influence-maximization-via-optimal-transport\/",
      "wordCount" : "2513",
      "genre" : [ ],
      "keywords" : [ ]
  }
  </script>
  
  
  </head>

<body>
  <a class="skip-link" href="#main">Skip to main</a>
  <main id="main">
  <div class="content">
    <header>
<p style="padding: 0;margin: 0;">
  <a href="../../">
    <b>Bloggin on Responsible AI</b>
    <span class="text-stone-500 animate-blink">▮</span>
  </a>
</p>
<ul style="padding: 0;margin: 0;">
  
  
  <li class="">
    <a href="../../posts/"><span>Post</span></a>
    
  <li class="">
    <a href="../../tutorial/"><span>Tutorial</span></a>
    
  <li class="">
    <a href="../../about/"><span>About</span></a>
    
  <li class="">
    <a href="../../articles/"><span>Articles</span></a>
    
  </li>
</ul>
</header>
<hr class="hr-list" style="padding: 0;margin: 0;">
    <section>
      <h2 class="post">Fairness in Social Influence Maximization via Optimal Transport</h2>
      <h3 id="authors-guillaume-marin-bertin--jaishan-burton-elmo">Authors: Guillaume MARIN-BERTIN &amp; Jaishan BURTON ELMO</h3>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#introduction">1. Introduction</a></li>
<li><a href="#mutual-fairness">2. Mutual Fairness: A New Metric</a>
<ul>
<li><a href="#why-make-a-new-metric">2.1 Why Make a New Metric?</a></li>
<li><a href="#proposed-fairness-metric">2.2 Proposed Fairness Metric</a></li>
<li><a href="#short-example">2.3 Short Example</a></li>
</ul>
</li>
<li><a href="#fairness-evaluation">3. Metric in Practice</a>
<ul>
<li><a href="#mutual-fairness-practice">3.1 Mutual Fairness in Practice</a></li>
<li><a href="#impact-of-beta">3.2 Impact of β</a></li>
</ul>
</li>
<li><a href="#s3d-algorithm">4. Improving Fairness with S3D</a>
<ul>
<li><a href="#stochastic-seed-selection-descent">4.1 Stochastic Seed Selection Descent (S3D)</a></li>
<li><a href="#experimentation">4.2 Experimentation</a></li>
<li><a href="#impact-of-s3d">4.3 Impact of S3D</a></li>
</ul>
</li>
<li><a href="#conclusion">5. Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
<p>This is a blog post about the article “Fairness in Social Influence Maximization via Optimal Transport” published by Shubham Chowdhary et al. in 2024 and available <a href="https://neurips.cc/virtual/2024/poster/94521"><strong>here</strong></a>.</p>
<h3 id="1-introduction"><a href="#introduction">1. Introduction</a></h3>
<p>In today’s digital society, social networks play a major role in how information spreads. Whether it is a public health campaign, a political message, or viral marketing, the ability to maximize influence is crucial. Companies, governments, and organizations leverage Influence Maximization (IM) algorithms to strategically select key individuals—called seeds—who will initiate a diffusion process, ensuring that information reaches the largest possible audience.</p>
<p>Imagine a scenario where a job-matching platform uses an Influence Maximization (IM) strategy to promote career opportunities to young professionals. The goal is to spread job postings efficiently across different professional communities. However, due to the structure of the social network, the algorithm selects key individuals (seeds) in such a way that:</p>
<ul>
<li>In 50% of cases, all the job opportunities are shared within a network of university graduates, while vocational school graduates receive none.</li>
<li>In the other 50% of cases, the opposite happens.</li>
</ul>
<p>At first glance, this might seem fair: both groups have an equal expected chance of seeing the job offers. However, in practice, one group is always entirely excluded in each scenario, creating a systemic disadvantage for those who miss out on critical career opportunities.</p>
<p>To fix this, researchers have tried adding fairness constraints to IM algorithms. The main ideas include:</p>
<ul>
<li><strong>Equity-based fairness</strong> (Stoica et al., 2020): Ensures that each group has the same expected proportion of influenced users.</li>
<li><strong>Max-min fairness</strong> (Fish et al., 2019; Zhu et al., 2019): Maximizes the minimum probability that any group receives information.</li>
<li><strong>Diversity-aware methods</strong> (Tsang et al., 2019): Ensure that no single group dominates the influence process.</li>
</ul>
<p>Despite these efforts, a fundamental issue remains: existing metrics treat groups independently and do not capture the joint probability of outreach. This means they can create the illusion of fairness while still allowing systematic exclusion of certain communities.</p>
<p>To address this, we propose a new fairness-aware framework that better distributes influence across communities:</p>
<ol>
<li><strong>Mutual Fairness</strong>: A better way to measure fairness, inspired by Optimal Transport. Instead of just looking at how much information each group gets in total, it ensures they receive the message at the same time.</li>
<li><strong>S3D Algorithm</strong>: A smarter way to choose influencers, balancing fairness and efficiency. It adjusts seed selection dynamically to improve fairness while still reaching as many people as possible.</li>
</ol>
<h3 id="2-mutual-fairness-a-new-metric"><a href="#mutual-fairness">2. Mutual Fairness: A New Metric</a></h3>
<h5 id="why-make-a-new-metric"><strong>Why make a new metric?</strong></h5>
<p>To understand why a new metric is necessary, let’s examine two situations where information propagation appears fair,we take the example of the introduction.</p>
<p>Consider two groups, C1 and C2, each with an outreach probability distribution:</p>
<p align="center">
  <a name="fig1"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure1.png" alt="figure1">
  <br>
  <i>Figure 1 : Outreach Probability Distribution for Groups C1 and C2</i>
</p>
<ul>
<li>δ<sub>0</sub> represents the case where the information is not transmitted.</li>
<li>δ<sub>1</sub> represents the case where the information is successfully received by the group.</li>
</ul>
<p>On average, both groups have a 50% chance of receiving the information, which might suggest a fair situation. However, this average hides significant differences in the actual distribution of information, as illustrated in the example below:</p>
<p align="center">
  <a name="fig2"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure2.png" alt="figure2">
  <br>
  <i>Figure 2 : Comparison of Two Joint Probability Distributions: γa and γb</i>
</p>
<p>First case (γa) :</p>
<ul>
<li>δ<sub>(0,0)</sub>: Neither group receives the information (50%).</li>
<li>δ<sub>(1,1)</sub>: Both groups receive the information simultaneously (50%).</li>
</ul>
<p>This configuration is fair because if one group does not receive the information, the other does not either.</p>
<p>Second case (γb) :</p>
<ul>
<li>δ<sub>(0,0)</sub>: Neither group receives the information (25%).</li>
<li>δ<sub>(1,1)</sub>: Both groups receive the information simultaneously (25%).</li>
<li>δ<sub>(0,1)</sub>: Group 1 does not receive the information, but Group 2 does (25%).</li>
<li>δ<sub>(1,0)</sub>: Group 1 receives the information, but Group 2 does not (25%).</li>
</ul>
<p>In this case, there is a 50% chance that only one group will receive the information, creating an inequality. However, the marginal averages remain the same (µ<sub>1</sub>=µ<sub>2</sub>=50%).</p>
<p>The distributions γ<sub>a</sub> and γ<sub>b</sub> are very different, yet the marginal averages do not capture these nuances. This highlights the need for a new metric to evaluate fairness more precisely, beyond simple averages.</p>
<h4 id="proposed-fairness-metric"><strong>Proposed fairness metric</strong></h4>
<p>The idea is to start from a joint probability measure γ rather than the marginal averages μ<sub>i</sub>. From γ, we aim to measure the distance between it and an ideal distribution γ*, where each group receives the same amount of information in all cases.</p>
<p>To illustrate this on a figure:</p>
<ul>
<li>The x-axis represents the amount of information received by group 1.</li>
<li>The y-axis represents the amount of information received by group 2.</li>
<li>The diagonal signifies that both groups receive exactly the same amount of information, which corresponds to the ideal sought.</li>
</ul>
<p>A movement perpendicular to the diagonal should be penalized, as it indicates an imbalance in the distribution of information between the groups. Similarly, we must penalize movement along the diagonal, as it affects efficiency. These costs are measured by Euclidean distance.
In the <a href="#fig3">Figure 3</a> below, we observe the transition from a distribution γa to a distribution γb, broken down into two components. One is dashed, representing the efficiency, and the other is solid, representing the fairness.</p>
<p align="center">
  <a name="fig3"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure3.png" alt="figure3">
  <br>
  <i>Figure 3 : Representation of the transport cost between two points (x1,x2) and(y1,y2) with an intermediate point z(x1,x2,y1,y2)</i>
</p>
<p>To define this cost, we use the following formula:</p>
<p align="center">
  <a name="fig4"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure4.png" alt="figure4">
  <br>
  <i>Figure 4 : Optimal Transport Cost Wcβ(γa,γb) Between Distributions γa and γb</i>
</p>
<p>We can draw an analogy with a move, where the goal is to transport items from House A to House B at the lowest possible cost, while ensuring that each item reaches its final destination according to W<sub>cβ</sub>(γ<sub>a</sub>, γ<sub>b</sub>).</p>
<ul>
<li>γ<sub>a</sub>: represents the list of items present in House A, specifying where they are located and in what quantity.</li>
<li>γ<sub>b</sub>: represents the list of items expected in House B, indicating where they should arrive and in what quantity.</li>
<li>c: This is the function that specifies the cost of moving an item from one location to another. In <a href="#fig5">figure 5</a>, we evaluate the transport cost between the point (x1, x2) and (y1, y2). We take z(x1, x2, y1, y2) as an intermediate point in the movement of an item to simplify the calculations. The transport cost is then defined as follows:</li>
</ul>
<p align="center">
  <a name="fig5"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure5.png" alt="figure5">
  <br>
  <i>Figure 5 : Cost Function cβ((x1,x2),(y1,y2)) Combining Fairness and Efficiency</i>
</p>
<ul>
<li>β: A coefficient used to weight the importance of fairness relative to efficiency.</li>
<li>π: This is the &ldquo;moving plan.&rdquo; It indicates how many items are moved from each location in House A to each location in House B.</li>
</ul>
<p>The goal is to find the plan π that minimizes the total moving cost while ensuring an equitable distribution of items between the destinations.</p>
<p>To arrive at the final formula, we start with the W<sub>cβ</sub> distance, which measures the transport cost between the current distribution γ and the ideal distribution γ*. Using the Euclidean norm to measure the distance between the points (x1, x2) and (y1, y2), we factor and generalize the terms to obtain the following equality:</p>
<p align="center">
  <a name="fig6"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure6.png" alt="figure6">
  <br>
  <i>Figure 6 : β-Fairness Metric: Combining Fairness and Efficiency in Distribution γ</i>
</p>
<p>This formula combines both fairness (measured by |x1 - x2|) and efficiency (measured by |x1 + x2 - 2|), weighted by the parameter β. The term max{1, 2 - 2β} ensures that the metric remains normalized between 0 and 1.</p>
<h4 id="short-example"><strong>Short example</strong></h4>
<p>To better understand the impact of this metric, let&rsquo;s examine several concrete cases of information distribution. We will compare different distributions and see how the mutual fairness metric allows us to evaluate them, considering both fairness and efficiency.</p>
<p>Consider the cases where γ = δ<sub>(0,0)</sub> and γ* = δ<sub>(1,1)</sub>. We also add an intermediate example γ<sub>ex</sub> = δ<sub>(0.8, 0.2)</sub>, where 80% of group 1 has access to the information, compared to only 20% for group 2.</p>
<p>By taking β = 0.6, which slightly favors fairness, we obtain the following results:</p>
<ul>
<li>fairness(γ*) &gt; fairness(γ), confirming that the information is better distributed when everyone receives it.</li>
<li>fairness(γ<sub>ex</sub>) ≈ fairness(γ), because although γ<sub>ex</sub> is twice as efficient (|0.8 + 0.2 - 2| = 1 versus |0 + 0 - 2| = 2), its score is heavily penalized by the lack of fairness. Indeed, one group is significantly favored over the other, making it as unbalanced as γ.</li>
</ul>
<p align="center">
  <a name="fig7"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure7.png" alt="figure7">
  <br>
  <i>Figure 7 : Fairness Scores for Different Distributions: γ, γex, and γ∗</i>
</p>
<h3 id="3-metric-in-practice"><a href="#fairness-evaluation">3. Metric in practice</a></h3>
<h4 id="mutual-fairness-in-practice"><strong>Mutual fairness in practice</strong></h4>
<p>We apply this metric to different datasets, which include social networks and communities partitioned into two groups. To do this, we load the dataset as a graph (V, E) and select a seedset S of size varying between 2 and 90. To diffuse the information, we use a probability p in the interval [0,1]. Since the process is stochastic, we repeat the operation 1000 times.</p>
<p>The results in <a href="#fig8">Figure 8</a> illustrate how information propagation varies depending on the probability p. In <a href="#fig8">Figure 8</a>(a), with p = 0.5, the information is disseminated in a way that is both efficient and equitable, with the groups being highly connected. The behavior is deterministic, with similar results in each iteration. In <a href="#fig8">Figure 8</a>(b), when p is reduced to 0.1, the propagation remains equitable but becomes less efficient, reaching on average only 20% of each group instead of nearly 100% as in (a).</p>
<p>In <a href="#fig8">Figure 8</a>(c), the outcomes are highly random: depending on the iteration, either one group receives all the information or the other, highlighting an inequity that is overlooked by traditional metrics. Finally, <a href="#fig8">Figure 8</a>(d) reveals a slight bias, where the variance of the distribution extends but does not remain centered on the diagonal. Although some metrics might consider this situation fair, mutual fairness provides more insight by evaluating fairness in each realization rather than just averaging it.</p>
<p align="center">
  <a name="fig8"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure8.png" alt="figure8">
  <br>
  <i>Figure 8 : Outreach Probability Distributions for Different Propagation Scenarios</i>
</p>
<h4 id="impact-of--β"><strong>Impact of  β</strong></h4>
<p>The results of the metric as a function of β are illustrated in Figure 9. Yellow indicates a low transport cost, while blue signals a deviation from the ideal.</p>
<p>When β = 0 <a href="#fig9">Figure 9</a>(a), only efficiency is considered: the information reaches the maximum number of people, but without regard for fairness (low transport cost in (1,1)). In contrast, with β = 1 (<a href="#fig9">Figure 9</a>(d)), only fairness is optimized, resulting in a perfectly equitable distribution but with reduced efficiency because the point (1,1) is no longer the only ideal one.</p>
<p>An optimal balance is achieved for β = 0.66 (<a href="#fig9">Figure 9</a>(c)), where the transport cost is minimized at the top-right of the plane. The further one moves away from this point, the higher the cost (blue areas), indicating a reduced level of optimization.</p>
<p>In summary, as β increases, fairness is prioritized, and getting closer to the diagonal reduces the transport cost, ensuring an equitable and efficient diffusion of information. Thus, the formula dynamically adjusts the trade-off between fairness and efficiency, with β acting as the weighting parameter that influences the distribution of the cost.</p>
<p align="center">
  <a name="fig9"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure9.png" alt="figure9">
  <br>
  <i>Figure 9 : Impact of β on Outreach Probability Distributions: Balancing Fairness and Efficiency</i>
</p>
<p>Now that we have our metric to determine if a distribution is fair and efficient, we want to focus on an algorithm to select the right seeds.</p>
<h3 id="4-improving-fairness-with-s3d"><a href="#s3d-algorithm">4. Improving Fairness with S3D</a></h3>
<h4 id="stochastic-seed-selection-descent-s3d">Stochastic Seed Selection Descent (S3D)</h4>
<p>While Mutual Fairness provides a way to measure fairness, Influence Maximization (IM) algorithms still need a method to optimize it without sacrificing outreach. S3D addresses this by dynamically adjusting seed selection to ensure a balanced information spread across all communities.</p>
<p>Instead of selecting influential nodes solely based on popularity, S3D explores alternative seed sets, optimizing both fairness and outreach through an iterative process:</p>
<p>The algorithm follows these key steps:</p>
<ol>
<li>
<p><strong>Initial Seed Selection</strong>:<br>
Influential nodes are chosen using traditional heuristics (e.g., degree centrality, community detection).</p>
</li>
<li>
<p><strong>Exploration of Neighboring States</strong>:<br>
The algorithm tests alternative seed sets by adding, swapping, or removing nodes.</p>
</li>
<li>
<p><strong>Fairness Evaluation</strong>:<br>
Each set is scored using the β-Fairness metric, which balances fairness and efficiency.</p>
</li>
<li>
<p><strong>Acceptance Criteria (Metropolis-Hastings Selection Rule)</strong>:<br>
The new seed set (S&rsquo;) is accepted with a probability defined as:</p>
</li>
</ol>
<p align="center">
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure12.png" alt="figure12">
</p>
<p>ensuring fairness-improving modifications are favored while maintaining some randomness.</p>
<ol start="5">
<li><strong>Convergence</strong>:<br>
The process runs until the fairness score stabilizes, achieving an optimal trade-off between fairness and outreach.</li>
</ol>
<h4 id="experiment">Experiment</h4>
<p>To evaluate the effectiveness of S3D, we compare it against traditional influence maximization algorithms on real-world social networks.</p>
<p>Dataset : Here we can take for example job-matching networks where nodes represent individuals looking for job opportunities and edges represent connections between people (e.g., same school, same company, LinkedIn network).</p>
<ul>
<li>Traditional IM methods (bas_d, bas_g) → Select highly connected influencers, ignoring fairness.</li>
<li>Fairness-aware heuristics (hrt_d, hrt_g) → Older fairness-based methods with static rules.</li>
<li>S3D (our approach) → Dynamically selects seeds to balance fairness and efficiency.</li>
</ul>
<ol>
<li>Fairness (Mutual Fairness Score) – Measures how equally information is distributed across different groups.</li>
<li>Efficiency (Total Outreach) – Measures how many people receive job opportunities in total.</li>
</ol>
<h4 id="does-s3d-improve-fairness">Does S3D Improve Fairness?</h4>
<p>Imagine a job-matching platform that aims to spread job opportunities equally across university graduates and vocational school graduates.</p>
<ul>
<li>Traditional IM methods pick influencers mostly from highly connected elite universities, leaving out vocational school graduates.</li>
<li>S3D Solution: By dynamically adjusting seed selection, S3D ensures that both communities receive job postings more equitably.</li>
</ul>
<p align="center">
  <a name="fig10"></a>
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure10.png" alt="figure10">
  <br>
  <i>Figure 10 : S3D Improvement Across Datasets and Parameters</i>
</p>
<ul>
<li>S3D (red points) significantly improves fairness compared to label-blind methods (blue).</li>
<li>The outreach distribution shifts towards the diagonal, meaning both groups receive information more equally.
Without S3D, certain communities miss job postings entirely in some scenarios.</li>
</ul>
<h4 id="how-does-s3d-balance-fairness-and-efficiency">How Does S3D Balance Fairness and Efficiency?</h4>
<p align="center">
  <img src="\images\Burton_Elmo-MARIN_BERTIN\images\figure11.png" alt="figure11">
</p>
<ul>
<li>S3D achieves the highest fairness scores (y-axis).</li>
<li>Minimal efficiency loss (x-axis) → Proves that fairness gains do not come at a high cost.</li>
<li>Insight: S3D is most useful in moderately connected networks (e.g., workplaces, schools).</li>
</ul>
<h4 id="impact-of-s3d">Impact of S3D</h4>
<p>S3D improves information dissemination by ensuring a more equitable distribution between different groups, without sacrificing efficiency. In our job-matching example, it allows graduates of professional schools to access the same opportunities as those from prestigious universities, thus leading to inequalities linked to the social network. Thanks to its adaptive approach, S3D stands out as an effective solution to correct the biases of traditional algorithms while maintaining a broad reach.</p>
<h3 id="5-conclusion"><a href="#conclusion">5. Conclusion</a></h3>
<p>As a conclusion, we can say that fairness in Social Influence Maximization is crucial to prevent systemic exclusion in information dissemination. Traditional methods often favor well-connected individuals, reinforcing existing inequalities. By introducing Mutual Fairness and the S3D algorithm, we provide a framework that balances fairness and efficiency, ensuring a more equitable outreach. Through our job-matching case study for example, we demonstrated that S3D significantly reduces bias while maintaining high influence spread. These results confirm that fairness-aware approaches can be both practical and impactful, making them essential for real-world applications such as hiring, education, or public awareness campaigns.</p>
<h3 id="references">References</h3>
<ol>
<li>Chowdhary, S., et al. (2024). Fairness in Social Influence Maximization via Optimal Transport. <em>NeurIPS 2024</em>. Available here <a href="https://neurips.cc/virtual/2024/poster/94521">https://neurips.cc/virtual/2024/poster/94521</a>.</li>
</ol>

      
      <div class="post-date">
        <span class="g time">March 15, 2025 </span> &#8729;
         
      </div>
      
    </section>
    
    <div id="comments">
      <script src="https://utteranc.es/client.js"
    repo=ZgotmplZ
    issue-term="pathname"
    theme=ZgotmplZ
    crossorigin="anonymous"
    async>
</script>

    </div>
    
  </div>
</main>
</body>
</html>
