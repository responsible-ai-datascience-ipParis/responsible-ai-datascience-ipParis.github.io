<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Liste - https://responsible-ai-datascience-ipParis.github.io/"><title>Posts | Bloggin on Responsible AI</title><meta name=description content="Bloggin on Responsible AI"><meta property="og:url" content="https://responsible-ai-datascience-ipParis.github.io/posts/"><meta property="og:site_name" content="Bloggin on Responsible AI"><meta property="og:title" content="Posts"><meta property="og:description" content="Bloggin on Responsible AI"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><meta itemprop=name content="Posts"><meta itemprop=description content="Bloggin on Responsible AI"><meta itemprop=datePublished content="2025-03-28T16:37:43+01:00"><meta itemprop=dateModified content="2025-03-28T16:37:43+01:00"><link rel=canonical href=https://responsible-ai-datascience-ipParis.github.io/posts/><link rel=icon href=https://responsible-ai-datascience-ipParis.github.io//assets/favicon.ico><link rel=dns-prefetch href=https://www.google-analytics.com><link href=https://www.google-analytics.com rel=preconnect crossorigin><link rel=alternate type=application/atom+xml title="Bloggin on Responsible AI" href=https://responsible-ai-datascience-ipParis.github.io//atom.xml><link rel=alternate type=application/json title="Bloggin on Responsible AI" href=https://responsible-ai-datascience-ipParis.github.io//feed.json><link rel="shortcut icon" type=image/png href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="><style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:#f5f5f5;color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5,strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a,a:visited{color:inherit}a:hover,a.heading-link{text-decoration:none}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:square}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:2;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:120px;width:120px;position:relative;margin:-10px 0 0 15px;float:right;border-radius:50%}</style></head><body><a class=skip-link href=#main>Skip to main</a><main id=main><div class=content><header><p style=padding:0;margin:0><a href=../><b>Bloggin on Responsible AI</b>
<span class="text-stone-500 animate-blink">â–®</span></a></p><ul style=padding:0;margin:0><li><a href=../posts/><span>Post</span></a><li><a href=../tutorial/><span>Tutorial</span></a><li><a href=../about/><span>About</span></a><li><a href=../articles/><span>Articles</span></a></li></ul></header><hr class=hr-list style=padding:0;margin:0><section><ul reversed class=list><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/xai_transformers/ title=XAI_transformers>XAI_transformers</a><hr class=hr-list><time class="g time" datetime=2025-03-28>28/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/activation_compression/ title="Neural Networks Forget to Forget: Fixing the Memory Problem With Tensor Decomposition">Neural Networks Forget to Forget: Fixing the Memory Problem With Tensor Decomposition</a><hr class=hr-list><time class="g time" datetime=2025-03-27>27/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/robust-classifiers-energy-based-models/ title="Robust Classifiers Energy Based Models">Robust Classifiers Energy Based Models</a><hr class=hr-list><time class="g time" datetime=2025-03-27>27/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/breaking-privacy-barriers-nonparametric-testing-in-federated-learning/ title="Breaking Privacy Barriers: Nonparametric Testing in Federated Learning">Breaking Privacy Barriers: Nonparametric Testing in Federated Learning</a><hr class=hr-list><time class="g time" datetime=2025-03-27>27/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/fairness-in-social-influence-maximization-via-optimal-transport/ title="Fairness in Social Influence Maximization via Optimal Transport">Fairness in Social Influence Maximization via Optimal Transport</a><hr class=hr-list><time class="g time" datetime=2025-03-15>15/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/impact-knowledge-distillation-model-interpretability/ title="Knowledge Distillation:  Boosting Interpretability in Deep Learning Models">Knowledge Distillation: Boosting Interpretability in Deep Learning Models</a><hr class=hr-list><time class="g time" datetime=2025-03-15>15/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/edge-pruning/ title="Unraveling the Mysteries of Language Models: The Power of Edge Pruning in Finding Transformer Circuits">Unraveling the Mysteries of Language Models: The Power of Edge Pruning in Finding Transformer Circuits</a><hr class=hr-list><time class="g time" datetime=2025-03-13>13/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/understanding_visual_feature_reliance_through_the_lens_of_complexity/ title="Understanding Visual Feature Reliance Through the Lens of Complexity">Understanding Visual Feature Reliance Through the Lens of Complexity</a><hr class=hr-list><time class="g time" datetime=2025-03-12>12/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/when_fairness_meets_privacy/ title="When Fairness Meets Privacy">When Fairness Meets Privacy</a><hr class=hr-list><time class="g time" datetime=2025-03-10>10/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/mixupdatacalibration/ title="Get a calibrated and efficient model with tailored data augmentation.">Get a calibrated and efficient model with tailored data augmentation.</a><hr class=hr-list><time class="g time" datetime=2025-03-09>09/03/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/bitfit/ title="BitFit: BIas-Term FIne-Tuning">BitFit: BIas-Term FIne-Tuning</a><hr class=hr-list><time class="g time" datetime=2025-02-19>19/02/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/selfie_with_me/ title="SelfIE: When Large Language Models Explain Their Own Thoughts">SelfIE: When Large Language Models Explain Their Own Thoughts</a><hr class=hr-list><time class="g time" datetime=2025-02-05>05/02/25</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/axiomatic_explanations/ title="Axiomatic Explanations for Visual Search, Retrieval and Similarity Learning">Axiomatic Explanations for Visual Search, Retrieval and Similarity Learning</a><hr class=hr-list><time class="g time" datetime=2024-03-28>28/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/privacy-amplification/ title="Privacy Amplification by Decentralization">Privacy Amplification by Decentralization</a><hr class=hr-list><time class="g time" datetime=2024-03-27>27/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/robust-or-fair/ title="Robust or Fair">Robust or Fair</a><hr class=hr-list><time class="g time" datetime=2024-03-27>27/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/xcm/ title="XCM, an explainable CNN for MTS classficiation">XCM, an explainable CNN for MTS classficiation</a><hr class=hr-list><time class="g time" datetime=2024-03-26>26/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/robustai_regmixup/ title=RobustAI_RegMixup>RobustAI_RegMixup</a><hr class=hr-list><time class="g time" datetime=2024-03-24>24/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/lambert-davy/ title="Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints">Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints</a><hr class=hr-list><time class="g time" datetime=2024-03-23>23/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/label-free-explainability/ title="Label-Free Explainability">Label-Free Explainability</a><hr class=hr-list><time class="g time" datetime=2024-03-17>17/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/adversarially_reweighted_learning/ title="Adversarially Reweighted Learning">Adversarially Reweighted Learning</a><hr class=hr-list><time class="g time" datetime=2024-03-04>04/03/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/packed-ensembles/ title="Packed Ensembles">Packed Ensembles</a><hr class=hr-list><time class="g time" datetime=2024-02-27>27/02/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/a-framework-to-learn-with-interpretation/ title="A Framework to Learn with Interpretation">A Framework to Learn with Interpretation</a><hr class=hr-list><time class="g time" datetime=2024-02-13>13/02/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/ntk-sap/ title="NTK-SAP: IMPROVING NEURAL NETWORK PRUNING BY ALIGNING TRAINING DYNAMICS">NTK-SAP: IMPROVING NEURAL NETWORK PRUNING BY ALIGNING TRAINING DYNAMICS</a><hr class=hr-list><time class="g time" datetime=2024-02-07>07/02/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/robustness-and-pag-the-converse/ title="Do Perceptually Aligned Gradients imply Robustness?">Do Perceptually Aligned Gradients imply Robustness?</a><hr class=hr-list><time class="g time" datetime=2024-02-07>07/02/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/neq/ title="To update or not to update? Neurons at equilibrium in deep models">To update or not to update? Neurons at equilibrium in deep models</a><hr class=hr-list><time class="g time" datetime=2024-02-07>07/02/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/optimal_transport_based_adversarial_patch/ title="Optimal Transport Based Adversarial Patch Attacks">Optimal Transport Based Adversarial Patch Attacks</a><hr class=hr-list><time class="g time" datetime=2024-02-03>03/02/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/statistical_minimax_rates_under_privacy/ title="Statistical Minimax Rates Under Privacy">Statistical Minimax Rates Under Privacy</a><hr class=hr-list><time class="g time" datetime=2024-01-31>31/01/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/transferability/ title="Measuring the Transferability of Pre-trained Models: a link with Neural Collapse Distances on Target Datasets">Measuring the Transferability of Pre-trained Models: a link with Neural Collapse Distances on Target Datasets</a><hr class=hr-list><time class="g time" datetime=2024-01-08>08/01/24</time></li><li><a class=link href=https://responsible-ai-datascience-ipParis.github.io/posts/blog-lora/ title></a><hr class=hr-list><time class="g time" datetime=0001-01-01>01/01/01</time></li></ul></section></div></main></body></html>