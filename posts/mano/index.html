<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Liste - https://responsible-ai-datascience-ipParis.github.io/"><title>MaNo | Bloggin on Responsible AI</title><meta name=description content="Bloggin on Responsible AI"><meta property="og:url" content="https://responsible-ai-datascience-ipParis.github.io/posts/mano/"><meta property="og:site_name" content="Bloggin on Responsible AI"><meta property="og:title" content="MaNo"><meta property="og:description" content="MaNo: A Smarter Way to Estimate Model Accuracy to Face Distribution Shifts Biais Authors: Alice Devilder, Sibylle Degos | Affiliations: IP Paris, Responsible AI | Published: 2025-03-28"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-10T12:22:37+01:00"><meta property="article:modified_time" content="2025-03-10T12:22:37+01:00"><meta itemprop=name content="MaNo"><meta itemprop=description content="MaNo: A Smarter Way to Estimate Model Accuracy to Face Distribution Shifts Biais Authors: Alice Devilder, Sibylle Degos | Affiliations: IP Paris, Responsible AI | Published: 2025-03-28"><meta itemprop=datePublished content="2025-03-10T12:22:37+01:00"><meta itemprop=dateModified content="2025-03-10T12:22:37+01:00"><meta itemprop=wordCount content="2692"><link rel=canonical href=https://responsible-ai-datascience-ipParis.github.io/posts/mano/><link rel=icon href=https://responsible-ai-datascience-ipParis.github.io//assets/favicon.ico><link rel=dns-prefetch href=https://www.google-analytics.com><link href=https://www.google-analytics.com rel=preconnect crossorigin><link rel=alternate type=application/atom+xml title="Bloggin on Responsible AI" href=https://responsible-ai-datascience-ipParis.github.io//atom.xml><link rel=alternate type=application/json title="Bloggin on Responsible AI" href=https://responsible-ai-datascience-ipParis.github.io//feed.json><link rel="shortcut icon" type=image/png href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="><style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:#f5f5f5;color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5,strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a,a:visited{color:inherit}a:hover,a.heading-link{text-decoration:none}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:square}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:2;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:120px;width:120px;position:relative;margin:-10px 0 0 15px;float:right;border-radius:50%}</style><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"posts","name":"MaNo","headline":"MaNo","alternativeHeadline":"","description":"\u003c!-- Custom CSS for MathJax and Tables --\u003e\n\u003cstyle type=\u0022text\/css\u0022\u003e\ncode.has-jax { \n    font: inherit;\n    font-size: 100%; \n    background: inherit; \n    border: inherit;\n}\n\ntable {\n    border-collapse: collapse;\n    width: 100%;\n}\nth, td {\n    padding: 8px;\n    text-align: center;\n    border-bottom: 1px solid #ddd;\n}\nth {\n    background-color: #f2f2f2;\n}\ntr:hover {\n    background-color: #f5f5f5;\n}\n\u003c\/style\u003e\n\u003c!-- MathJax Configuration --\u003e\n\u003cscript type=\u0022text\/x-mathjax-config\u0022\u003e\nMathJax.Hub.Config({\n    tex2jax: {\n        inlineMath: [[\u0027$\u0027,\u0027$\u0027], [\u0027\\\\(\u0027,\u0027\\\\)\u0027]],\n        displayMath: [[\u0027$$\u0027,\u0027$$\u0027], [\u0027\\\\[\u0027,\u0027\\\\]\u0027]],\n        skipTags: [\u0027script\u0027, \u0027noscript\u0027, \u0027style\u0027, \u0027textarea\u0027, \u0027pre\u0027] \/\/ Removed \u0027code\u0027 entry\n    }\n});\nMathJax.Hub.Queue(function() {\n    var all = MathJax.Hub.getAllJax(), i;\n    for(i = 0; i \u003c all.length; i \u002b= 1) {\n        all[i].SourceElement().parentNode.className \u002b= \u0027 has-jax\u0027;\n    }\n});\n\u003c\/script\u003e\n\u003c!-- Load MathJax --\u003e\n\u003cscript type=\u0022text\/javascript\u0022 \n    src=\u0022https:\/\/cdnjs.cloudflare.com\/ajax\/libs\/mathjax\/2.7.7\/MathJax.js?config=TeX-AMS_HTML-full\u0022\u003e\n\u003c\/script\u003e\n\u003ch1 style=\u0022font-size: 28px; text-align: center;\u0022\u003e MaNo: A Smarter Way to Estimate Model Accuracy to Face Distribution Shifts Biais \u003c\/h1\u003e\n\u003cstyle\u003e\n.hr-line {\n    border: none;\n    height: 2px;\n    background-color: black;\n    margin: 10px 0;\n}\n\u003c\/style\u003e\n\u003chr class=\u0022hr-line\u0022\u003e\n\u003cp\u003e\u003cstrong\u003eAuthors:\u003c\/strong\u003e Alice Devilder, Sibylle Degos | \u003cstrong\u003eAffiliations:\u003c\/strong\u003e IP Paris, Responsible AI | \u003cstrong\u003ePublished:\u003c\/strong\u003e 2025-03-28\u003c\/p\u003e","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/responsible-ai-datascience-ipParis.github.io\/posts\/mano\/"},"author":{"@type":"Person","name":""},"creator":{"@type":"Person","name":""},"accountablePerson":{"@type":"Person","name":""},"copyrightHolder":"Bloggin on Responsible AI","copyrightYear":"2025","dateCreated":"2025-03-10T12:22:37.00Z","datePublished":"2025-03-10T12:22:37.00Z","dateModified":"2025-03-10T12:22:37.00Z","publisher":{"@type":"Organization","name":"Bloggin on Responsible AI","url":"https://responsible-ai-datascience-ipParis.github.io/","logo":{"@type":"ImageObject","url":"https:\/\/responsible-ai-datascience-ipParis.github.io\/assets\/favicon.ico","width":"32","height":"32"}},"image":"https://responsible-ai-datascience-ipParis.github.io/assets/favicon.ico","url":"https:\/\/responsible-ai-datascience-ipParis.github.io\/posts\/mano\/","wordCount":"2692","genre":[],"keywords":[]}</script></head><body><a class=skip-link href=#main>Skip to main</a><main id=main><div class=content><header><p style=padding:0;margin:0><a href=../../><b>Bloggin on Responsible AI</b>
<span class="text-stone-500 animate-blink">▮</span></a></p><ul style=padding:0;margin:0><li><a href=../../posts/><span>Post</span></a><li><a href=../../tutorial/><span>Tutorial</span></a><li><a href=../../about/><span>About</span></a><li><a href=../../articles/><span>Articles</span></a></li></ul></header><hr class=hr-list style=padding:0;margin:0><section><h2 class=post>MaNo</h2><style type=text/css>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit}table{border-collapse:collapse;width:100%}th,td{padding:8px;text-align:center;border-bottom:1px solid #ddd}th{background-color:#f2f2f2}tr:hover{background-color:#f5f5f5}</style><script type=text/x-mathjax-config>
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // Removed 'code' entry
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML-full"></script><h1 style=font-size:28px;text-align:center>MaNo: A Smarter Way to Estimate Model Accuracy to Face Distribution Shifts Biais</h1><style>.hr-line{border:none;height:2px;background-color:#000;margin:10px 0}</style><hr class=hr-line><p><strong>Authors:</strong> Alice Devilder, Sibylle Degos | <strong>Affiliations:</strong> IP Paris, Responsible AI | <strong>Published:</strong> 2025-03-28</p><hr class=hr-line><h2 id=table-of-contents><strong>Table of Contents</strong></h2><ul><li><a href=#section-0.0>Introduction</a><ul><li><a href=#section-0.1>Why Do Logits Matter For Generalization Performance?</a></li><li><a href=#section-0.2>Why Does softmax normalisation fail to alleviate the overconfidence issues of logits-based methods?</a></li></ul></li><li><a href=#section-1>Introducing MANO: A Two-Step Approach</a><ul><li><a href=#section-1.1>Normalization with Softrun</a></li><li><a href=#section-1.2>Aggregation Using Matrix Norms</a></li></ul></li><li><a href=#section-2>Pseudo-Code of MANO and its implementation</a></li><li><a href=#section-3>Empirical Success: MANO vs. Baselines</a></li><li><a href=#section-4>Applications and Future Directions</a></li><li><a href=#section-5>Conclusion</a></li></ul><p>This is a blog post about the paper <em><strong>MaNo: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts</strong></em>, published by <em>Renchunzi Xie</em>, <em>Ambroise Odonnat</em>, <em>Vasilii Feofanov</em>, <em>Weijian Deng</em>, <em>Jianfeng Zhang</em> and <em>Bo An</em> in November 2024 and avalaible on <a href=https://arxiv.org/abs/2405.18979>arXiv</a>.</p><hr><p>Usually, in machine learning, data is divided into train/test sets. But you already know that! The problem is that there is often a shift in the way data is distributed or collected between train and test set. This shift distribution can disrupt predictive models, and can be a risk for AI safety.</p><p>To illustrate, imagine a pedestrian image recognition model used for autonomous cars. Trained on images of pedestrians during the day, fails to detect pedestrians at night due to a shift in data distribution, leading to accidents.</p><p>Traditional approaches to evaluate models rely on costly, computationally expensive ground-truth labels, making the evaluation difficult. Thanks to the solution in the paper “<em><strong>MANO: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts</strong></em>”, we can estimate model accuracy without labeled test data. MANO (Matrix Norm-based Accuracy Estimation) is presented as a novel solution, leveraging logits (the raw outputs of a model) to infer confidence and predict accuracy in an unsupervised manner. It is splitted in two steps:</p><ul><li><strong>Softrun</strong> normalization to calibrate logits</li><li><strong>Lp norm</strong> to quantify decision boundary distances.</li></ul><p>Let’s deep into MANO ! You will understand the theoretical foundations and empirical success that make this method very interesting to estimate the accuracy in an unsupervised environment.</p><h2 id=section-0.0><strong>Introduction</strong></h2><p>A common method for estimating accuracy without labels is analyzing a model’s <strong>logits</strong>, the raw outputs before softmax. However, existing methods suffer from overconfidence issues and biased predictions under distribution shifts.</p><h3 id=section-0.1><strong>Let’s understand why Logits Matter For Generalization Performance !</strong></h3><p><strong>Logits</strong> represent the raw values generated by a model before they are passed through a normalization function, such as softmax. In simple terms, in classification tasks, logits are the <strong>raw scores</strong> associated with each class that help evaluate the model&rsquo;s performance. These scores are particularly important for measuring a model&rsquo;s generalization ability, i.e., its capacity to make accurate predictions on new, unseen data.</p><p>Mathematically, for a given input $x$, the model computes logits as:</p><p>$$ q = f(x) = (\omega_k^T z)_k \in \mathbb{R}^K $$</p><p>where $z$ is the learned feature representation, $\omega_k$ is the classifier’s weight vector, and $K$ is the number of classes. The magnitude of logits correlates with the distance to decision boundaries, making them valuable for accuracy estimation.</p><p>The concept of logits is based on the <strong>low-density separation</strong> assumption. According to this assumption, data points located near the decision boundaries of the model (i.e., where the model is uncertain) are more likely to be misclassified. This means that a model may struggle to make reliable predictions for these ambiguous examples. By analyzing logits, we can gain insights into the model&rsquo;s confidence levels and its ability to generalize to unseen data.</p><p>Now you understand that logits are very important for generalisation performance, but one question remains&mldr;</p><h3 id=section-0.2><strong>Why Does softmax normalisation fail to alleviate the overconfidence issues of logits-based methods?</strong></h3><p><strong>Softmax normalization</strong> is commonly used to transform these logits into <strong>class probabilities</strong>, which makes the predictions interpretable. By applying softmax, logits are converted into values between 0 and 1, representing the probability that each class is correct.</p><p style=display:inline-block;vertical-align:middle>Mathematically, softmax is defined as:</p><figure id=my-fig class=numbered style=display:inline-block;vertical-align:middle;margin-left:10px><img src=../../images/Mano/softmax_img.png class=align-center style=width:250px;height:auto></figure><p>However, this approach has a major issue: it is <strong>sensitive to prediction bias</strong> and can lead to <strong>overconfidence</strong>. In other words, if a model generates very high logits for a class (indicating strong confidence in its prediction), but that prediction is incorrect, it can skew the results. This phenomenon is largely due to the <strong>exponential function</strong> in the softmax formula, which amplifies the differences between logits. This can lead to significant errors, especially when the model is overly confident without being accurate.</p><p>This overconfidence bias is a critical issue when evaluating a model’s performance.
To address this challenge, the paper introduces <strong>MANO</strong>, a novel method that leverages logits to estimate model accuracy without labeled data.</p><h2 id=section-1><strong>Introducing MANO: A Two-Step Approach</strong></h2><p>MANO addresses these challenges through a two-step process: <strong>Normalization with Softrun</strong> and <strong>Aggregation using Matrix Norms</strong>. Here is a scheme so you can visualize the process :</p><p><img src=../../images/Mano/Mano_schema.png alt="Mano schema" loading=lazy decoding=async class=full-width></p><h3 id=section-1.1><strong>1. Normalization with Softrun</strong></h3><p>As explained before, Softmax is a very common activation function to transform logits into probabilities. But its exponential nature exaggerates differences between logits, making the model appear more confident than it actually is.</p><p>First, let’s calculate $\Phi(\mathcal{D}_{test})$, a function that measures the amount of complete information on the logits.</p><p>$\Phi(\mathcal{D}_{test}) =$</p><p>$$ -\frac{1}{NK} \sum_{j=1}^{N} \sum_{k=1}^{K} \log \left(\frac{\exp(q_{j,k})}{\sum_{j=1}^{K} \exp(\mathbf{q}_{i,j})} \right) $$</p><p>The general formula has the same structure of the softmax but with a dynamic $v(\mathbf{q}_i)$:</p><p>$$ \sigma(q_i) = \frac{v(q_i)}{\sum_{k=1}^{K} v(q_i)_k} \in \Delta_K$$</p><p>Thanks to $\Phi(\mathcal{D}_{test})$, it will determine whether to apply a Taylor or softmax normalization term. The function $v(q)$ is defined as:</p><figure id=my-fig_eq_v class=numbered><img src=../../images/Mano/equation_v.png class=align-center><p style=text-align:center></p></figure><p>When the model’s predictions are unreliable, Softrun applies a Taylor approximation rather than the softmax. The Taylor approximation smooths out the effect of large logits, preventing the model from being overly confident in any particular prediction. By contrast, when the dataset is well-calibrated, the function behaves like softmax, preserving probability distributions where confidence is warranted.</p><figure id=my-fig class=numbered style=float:left;margin-left:10px;width:50%><img src=../../images/Mano/Lp_norm_schema.png class=align-center style=width:100%;height:auto><p style=text-align:center></p></figure><p>To recapitulate, there are 3 studied cases :</p><p><strong>Case 1 - High Confidence, Low Bias</strong> When the model is both confident and has a low bias, its logits are highly reliable. This is an ideal case where we can safely apply softmax normalization without worrying about introducing additional bias. The softmax probabilities will be well-calibrated, and no extra correction is needed.</p><p><strong>Case 2 - Low Confidence, High Bias</strong> If the model is not confident in its predictions and shows high bias, it means that the predictions are both uncertain and systematically inaccurate. In this situation, we use the Taylor normalization. The smooth properties of Taylor normalization help mitigate bias while maintaining better uncertainty estimation.</p><p><strong>Case 3 - Grey zone</strong> Sometimes, the model&rsquo;s behavior doesn’t fit perfectly into one category. In this scenario, different examples fall into different cases, making it difficult to determine the best normalization method. In these cases, it is safer to use Taylor normalization because it avoids exacerbating bias in the same way softmax does.</p><p>Besides, the output of this first step is scaled logits: $Q_i = \sigma(q_i) \in \Delta_K$.</p><h3 id=section-1.2><strong>2. Aggregation Using Matrix Norms</strong></h3><p>After normalization, MANO <strong>aggregates</strong> the logits using the <strong>Lp norm</strong> of the matrix $Q$, defined as:</p><figure id=my-fig class=numbered><img src=../../images/Mano/equation_s.png class=align-center><p style=text-align:center></p></figure><p>where:</p><ul><li>$Q$ represents the matrix of softmax probabilities,</li><li>$N$ is the number of test samples,</li><li>$K$ is the number of classes,</li><li>$σ(q_i)_k$ is the result of the step of normalisation seen before,</li><li>$p$ is a hyperparameter controlling the sensitivity of the aggregation.</li></ul><p>The normalization factor $\frac{1}{^p\sqrt{NK}}$​ ensures that $S(f,D_{test})$ is independent of dataset size and number of classes, providing a standardized metric across different test distributions.</p><p><strong>Advantages of Using the Lp​ Norm</strong>
One of the main advantages of the Lp​ norm over the Nuclear Norm is its <strong>computational efficiency</strong>. The Lp​ norm is straightforward to compute, requiring only element-wise operations and summations. In contrast, nuclear norm-based methods involve Singular Value Decomposition (SVD), which is computationally expensive and less scalable for large datasets.</p><p><strong>Effect of p on Aggregation Sensitivity</strong></p><figure id=my-fig class=numbered style=float:right;margin-right:10px;width:45%><img src=../../images/Mano/impact_Lp_norm.png class=align-center style=width:100%;height:auto><p style=text-align:center></p></figure><p>In the formula, the parameter p controls the sensitivity of the metric to high-confidence predictions:</p><ul><li>For <strong>small p</strong>, all predictions contribute relatively equally to the final score.</li><li>As <strong>p increases</strong>, the aggregation puts more emphasis on confident predictions (i.e., softrun values close to 1).</li><li>In the case <strong>p→∞</strong>, the norm becomes equivalent to the maximum prediction confidence.</li></ul><p>In practice, the authors of the paper conducted a sensitivity analysis on 5 datasets using ResNet-18 and found that $p=4$ provides the best balance between capturing model confidence and maintaining robustness. This is illustrated in the experimental results on the right.</p><p>Let&rsquo;s see now how to implement MANO in practice!</p><h2 id=section-2><strong>Pseudo-Code of MANO and its implementation</strong></h2><p>Before diving into implementation, it’s important to understand the logic behind the MANO algorithm for unsupervised accuracy estimation.</p><p><img src=../../images/Mano/algorithm_mano.png alt="Algorithm 1: MANO Pseudocode" loading=lazy decoding=async class=full-width></p><p>The pseudocode above outlines the core procedure: given a model and an unlabeled test set, the method first determines the best way to normalize the model&rsquo;s logits, either using softmax or the novel alternative softrun on an entropy-based criterion (see <a href=#section-1.1>Section 1.1</a>). Then, it iterates over each sample in the test set, collects the normalized predictions into a matrix, and finally computes an estimation score using the matrix’s normalized L_p norm (see <a href=#section-1.2>Section 1.2</a>). This score correlates with the model&rsquo;s true accuracy, even without access to ground truth labels.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>torch</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>algs.base_alg</span> <span style=color:#f92672>import</span> <span style=color:#111>Base_alg</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>torch.nn</span> <span style=color:#00a8c8>as</span> <span style=color:#111>nn</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the MaNo class, inheriting from Base_alg</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>class</span> <span style=color:#75af00>MaNo</span><span style=color:#111>(</span><span style=color:#111>Base_alg</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Method to evaluate the model&#39;s performance</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>def</span> <span style=color:#75af00>evaluate</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Set the base model to training mode</span>
</span></span><span style=display:flex><span>        <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>base_model</span><span style=color:#f92672>.</span><span style=color:#111>train</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Initialize an empty list to store scores</span>
</span></span><span style=display:flex><span>        <span style=color:#111>score_list</span> <span style=color:#f92672>=</span> <span style=color:#111>[]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Iterate through the validation data loader</span>
</span></span><span style=display:flex><span>        <span style=color:#00a8c8>for</span> <span style=color:#111>batch_idx</span><span style=color:#111>,</span> <span style=color:#111>batch_data</span> <span style=color:#f92672>in</span> <span style=color:#111>enumerate</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>val_loader</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Extract inputs and labels from the batch</span>
</span></span><span style=display:flex><span>            <span style=color:#111>inputs</span><span style=color:#111>,</span> <span style=color:#111>labels</span> <span style=color:#f92672>=</span> <span style=color:#111>batch_data</span><span style=color:#111>[</span><span style=color:#ae81ff>0</span><span style=color:#111>],</span> <span style=color:#111>batch_data</span><span style=color:#111>[</span><span style=color:#ae81ff>1</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Move inputs and labels to the specified device (e.g., GPU or CPU)</span>
</span></span><span style=display:flex><span>            <span style=color:#111>inputs</span><span style=color:#111>,</span> <span style=color:#111>labels</span> <span style=color:#f92672>=</span> <span style=color:#111>inputs</span><span style=color:#f92672>.</span><span style=color:#111>to</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>device</span><span style=color:#111>),</span> <span style=color:#111>labels</span><span style=color:#f92672>.</span><span style=color:#111>to</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>device</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Disable gradient computation for evaluation</span>
</span></span><span style=display:flex><span>            <span style=color:#00a8c8>with</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>no_grad</span><span style=color:#111>():</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># Pass inputs through the base model to get raw outputs (logits)</span>
</span></span><span style=display:flex><span>                <span style=color:#111>outputs</span> <span style=color:#f92672>=</span> <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>base_model</span><span style=color:#111>(</span><span style=color:#111>inputs</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># Apply the scaling method (e.g., Softrun normalization) to logits</span>
</span></span><span style=display:flex><span>                <span style=color:#111>outputs</span> <span style=color:#f92672>=</span> <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>scaling_method</span><span style=color:#111>(</span><span style=color:#111>outputs</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>                <span style=color:#75715e># Compute the Lp norm of the scaled logits</span>
</span></span><span style=display:flex><span>                <span style=color:#111>score</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>norm</span><span style=color:#111>(</span><span style=color:#111>outputs</span><span style=color:#111>,</span> <span style=color:#111>p</span><span style=color:#f92672>=</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>args</span><span style=color:#111>[</span><span style=color:#d88200>&#39;norm_type&#39;</span><span style=color:#111>])</span> <span style=color:#f92672>/</span> <span style=color:#111>(</span>
</span></span><span style=display:flex><span>                            <span style=color:#111>(</span><span style=color:#111>outputs</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>[</span><span style=color:#ae81ff>0</span><span style=color:#111>]</span> <span style=color:#f92672>*</span> <span style=color:#111>outputs</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>[</span><span style=color:#ae81ff>1</span><span style=color:#111>])</span> <span style=color:#f92672>**</span> <span style=color:#111>(</span><span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>args</span><span style=color:#111>[</span><span style=color:#d88200>&#39;norm_type&#39;</span><span style=color:#111>]))</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Append the computed score to the score list</span>
</span></span><span style=display:flex><span>            <span style=color:#111>score_list</span><span style=color:#f92672>.</span><span style=color:#111>append</span><span style=color:#111>(</span><span style=color:#111>score</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Convert the list of scores to a NumPy array and compute the mean</span>
</span></span><span style=display:flex><span>        <span style=color:#111>scores</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>Tensor</span><span style=color:#111>(</span><span style=color:#111>score_list</span><span style=color:#111>)</span><span style=color:#f92672>.</span><span style=color:#111>numpy</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>        <span style=color:#00a8c8>return</span> <span style=color:#111>scores</span><span style=color:#f92672>.</span><span style=color:#111>mean</span><span style=color:#111>()</span>
</span></span></code></pre></div><p>The python implementation reflects this logic efficiently using PyTorch. In this code, the <code>MaNo</code> class inherits from a base algorithm class (<code>Base_alg</code>). The <code>evaluate</code> method is responsible for evaluating the model&rsquo;s performance on a validation dataset. It iterates through the validation data loader, processes the inputs through the model, applies the scaling method, computes the Lp norm of the scaled logits, and returns the mean score.
The <code>scaling_method</code> function is where the normalization takes place, and the Lp norm is computed using the specified norm type (e.g., L2 norm). The code is designed to be efficient and leverages PyTorch for GPU acceleration.</p><p>Now, let’s dive into the empirical results of MaNo across various datasets.</p><h2 id=section-3><strong>Empirical Success: MANO vs. Baselines</strong></h2><p>MANO has been evaluated against <strong>11 baseline methods</strong>, including Rotation Prediction (Rotation) <a href=#rotation>[2]</a>, Averaged Confidence (ConfS core) <a href=#confscore>[3]</a> and Entropy <a href=#entropy>[4]</a> amongst others. To show the versatility of Mano across different architectures, it has been evaluated across 3 different neural network architectures: ResNet18, ResNet50 <a href=#resnet50>[5]</a>, and WRN-50-2. The experiments were conducted on a range of classification tasks, including image recognition benchmarks such as CIFAR-10, CIFAR-100, TinyImageNet, and ImageNet, as well as domain adaptation datasets like PACS and Office-Home.</p><p>In this comprehensive evaluation, the authors have considered 3 types of distribution shifts: <strong>synthetic shifts</strong>, where models were tested against artificially corrupted images; <strong>natural shifts</strong>, which involved datasets collected from different distributions than the training data; and <strong>subpopulation shifts</strong>, where certain classes or groups were underrepresented in the training data. To evaluate Mano under synthetic shifts, the authors have used CIFAR-10C, CIFAR-100C, ImageNet-C, and TinyImageNet-C, covering various corruption types and severity levels. For natural shifts, they tested on OOD datasets from PACS, Office-Home, DomainNet, and RR1 WILDS. To assess subpopulation shifts, they used the BREEDS benchmark, including Living-17, Nonliving-26, Entity-13, and Entity-30 from ImageNet-C.</p><figure id=my-fig class=numbered style=float:left;margin-left:10px;width:45%><img src=../../images/Mano/R2_scores.png class=align-center style=width:100%;height:auto></figure><p>On the left, we can see a box plot of $R^2$ distribution showing the estimation robustness across different shifts on all datasets except ImageNet, using ResNet18. We observe that MANO consistently outperformed existing methods in all three scenarios (achieving the highest median estimation performance), demonstrating its robustness to varying degrees of domain shifts. For more details, you can find numerical results for the different shifts in the paper. For instance, MANO achieves $R^2 > 0.960$ and $ρ > 0.990$ under subpopulation shift, where as the performance of other baselines does not reach such consistently high levels.</p><p>Additionally, in the figure below, we can see a scatter plot illustrating the outperforming results of Mano on natural shift compared to Dispersion Score and ProjNorm on Entity-18 using ResNet-18.</p><figure id=my-fig class=numbered><img src=../../images/Mano/results_plot.png class=align-center style=width:100%;height:auto><p style=text-align:center></p></figure><p>We can observe that MANO scores demonstrate a robust linear relationship with ground-truth OOD errors, whereas other state-of-the-art baselines tend to produce biased estimations, particularly for high test errors. Therefore, MANO significantly boosts performance under the natural shift.</p><p>Unlike traditional approaches that either rely on softmax probabilities or require retraining on new distributions, MANO provides a label-free and computation-efficient accuracy estimation method that scales well across different domains. By using <strong>Softrun normalization and matrix norm aggregation</strong>, MANO achieves a stronger correlation with actual accuracy, ensuring that model performance estimates remain reliable even when faced with extreme distribution shifts.</p><h2 id=section-4><strong>Applications and Future Directions</strong></h2><p>Let&rsquo;s discuss now how MANO can be applied in practice, the benefit of combining Softrun with other estimation baselines, and the limitations of this approach.</p><p>One crucial application in the real world is <strong>deployment risk estimation</strong>, where real-time insights into model reliability can be obtained without costly manual labeling. This is particularly useful for models deployed in dynamic environments, such as healthcare and autonomous systems, where distribution shifts are frequent and unpredictable.</p><p>Now, what is the impact of Softrun on other estimation baselines? The authors have conducted an ablation study to assess how Softrun enhances the performance of Nuclear <a href=#nuclear>[6]</a>, ConfScore <a href=#confscore>[3]</a>, and MANO. As shown in the paper, Softrun significantly improves Nuclear’s $R^2$ score, particularly in datasets like Office-Home, where its performance increases from $0.692$ to $0.826$. These findings suggest that integrating Softrun into existing methods can improve their estimation reliability, making them more robust to poorly calibrated datasets.</p><p>Despite its strong theoretical foundation and empirical performance, MANO has certain limitations. One challenge is its reliance on the selection criterion parameter $η$ in Equation <a href=#my-fig_eq_v>v</a>, which requires careful tuning. To overcome this dependency, future research will focus on developing an automated approach to selecting the optimal normalization function without manual hyperparameter adjustments. Additionally, if multiple validation sets are available, as suggested in previous works (<a href=#nuclear>[5]</a>; <a href=#other>[6]</a>), the selection of $η$ could be refined based on these datasets, further improving MANO’s adaptability and robustness across different tasks.</p><h2 id=section-5><strong>Conclusion</strong></h2><p>MANO represents a significant breakthrough in unsupervised accuracy estimation. By addressing logit overconfidence and introducing Softrun normalization, MANO provides a scalable, robust, and theoretically grounded approach for evaluating model accuracy under distribution shifts.</p><p>🔗 <strong>Code available at:</strong> <a href=https://github.com/Renchunzi-Xie/MaNo>MANO GitHub Repository</a></p><p>To sum up, MANO is a jump toward trustworthy AI deployment !</p><hr><h2 id=references><strong>References</strong></h2><p><span id=mano>1.</span> Renchunzi Xie and Ambroise Odonnat and Vasilii Feofanov and Weijian Deng and Jianfeng Zhang and Bo An,
MANO: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts,
arXiv:2405.18979, 2024.</p><p><span id=rotation>2.</span> Deng, W., Gould, S., and Zheng, L. (2021). What does rotation prediction tell us about classifier accuracy under varying testing environments? In International Conference on Machine Learning (ICML), pages 2579–2589.</p><p><span id=confscore>3.</span> Hendrycks, D. and Gimpel, K. (2016). A baseline for detecting misclassified and out-of-distribution examples in neural networks. arXiv preprint arXiv:1610.02136.</p><p><span id=entropy>4.</span> Guillory, D., Shankar, V., Ebrahimi, S., Darrell, T., and Schmidt, L. (2021). Predicting with confidence on unseen distributions. In Proceedings of the IEEE/CVF international Conference on Computer Vision (ICCV), pages 1134–1144.</p><p><span id=resnet50>5.</span> He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778.</p><p><span id=nuclear>5.</span> Deng, W., Suh, Y., Gould, S., and Zheng, L. (2023). Confidence and dispersity speak: Characterising prediction matrix for unsupervised accuracy estimation. arXiv preprint arXiv:2302.01094.</p><p><span id=other>6.</span> Deng, W. and Zheng, L. (2021). Are labels always necessary for classifier accuracy evaluation? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 15069–15078.</p><div class=post-date><span class="g time">March 10, 2025 </span>&#8729;</div></section><div id=comments><script src=https://utteranc.es/client.js repo=ZgotmplZ issue-term=pathname theme=ZgotmplZ crossorigin=anonymous async></script></div></div></main></body></html>